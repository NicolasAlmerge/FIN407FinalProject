{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "THIS CODE HAS NOT BEEN RAN/TESTED, PLEASE DO SO\n",
    "We replace the lines:\n",
    "\n",
    "  # Cross-validation scores\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring=\"r2\")\n",
    "    print(f\"{model_name} Cross-Validation R²: {scores.mean():.3f} ± {scores.std():.3f}\")\n",
    "\n",
    "of [4] of 4. Training of Predictors.ipynb by the following:\n",
    "\n",
    "1. Create a New Function for Walk-Forward Validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_walk_forward_validation(\n",
    "    model_name: str,\n",
    "    model: Any,\n",
    "    X_df: pd.DataFrame,\n",
    "    y: pd.Series,\n",
    "    test_size: float = 0.1,\n",
    "    seed: int = 0,\n",
    "    custom_performance_metric=None,\n",
    "):\n",
    "    \"\"\"\n",
    "    Performs walk-forward validation on a given model and returns performance metrics.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): Name of the model.\n",
    "        model (Any): The machine learning model to be evaluated.\n",
    "        X_df (pd.DataFrame): The feature data.\n",
    "        y (pd.Series): The target variable (e.g., portfolio returns).\n",
    "        test_size (float, optional): Proportion of data for testing in each step. Defaults to 0.1.\n",
    "        seed (int, optional): Random seed for reproducibility. Defaults to 0.\n",
    "        custom_performance_metric (function, optional): A user-defined function for calculating a custom metric.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing performance metrics (e.g., errors, custom metrics).\n",
    "    \"\"\"\n",
    "\n",
    "    OUTPUT_DIR = \"results\"  # Adjust directory path as needed\n",
    "\n",
    "    # Data preparation (can be moved to a separate function if needed)\n",
    "    X = prepare_data(X_df)  # Assuming you have a prepare_data function for normalization/PCA\n",
    "\n",
    "    # Walk-forward validation loop\n",
    "    predictions = []\n",
    "    errors = []\n",
    "    actual_values = []\n",
    "    for i in range(test_size, len(y)):\n",
    "        train_X = X[:i]\n",
    "        train_y = y[:i]\n",
    "        test_X = X[i:i + 1]\n",
    "        test_y = y[i:i + 1]\n",
    "\n",
    "        model.fit(train_X, train_y)\n",
    "        prediction = model.predict(test_X)[0]\n",
    "        predictions.append(prediction)\n",
    "        actual_values.append(test_y.values[0])\n",
    "        error = mean_squared_error(test_y.values[0], prediction)\n",
    "        errors.append(error)\n",
    "\n",
    "    # Calculate additional performance metrics (if needed)\n",
    "    if custom_performance_metric is not None:\n",
    "        custom_metric_value = custom_performance_metric(actual_values, predictions)\n",
    "    else:\n",
    "        custom_metric_value = None\n",
    "\n",
    "    # Store results in a dictionary\n",
    "    results = {\n",
    "        \"model_name\": model_name,\n",
    "        \"errors\": errors,\n",
    "        \"custom_metric\": custom_metric_value,  # Replace with actual metric name\n",
    "    }\n",
    "\n",
    "    # Save results (optional)\n",
    "    # ... (code to save results to a file or database)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Call the Walk-Forward Function:\n",
    "\n",
    "Keep your existing run_model_and_plot function for its intended purpose (traditional train-test split evaluation).\n",
    "When you want to perform walk-forward validation, call the new perform_walk_forward_validation function after preparing your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have prepared your data (X_df, y) and model (model)\n",
    "\n",
    "# Use run_model_and_plot for traditional evaluation (optional)\n",
    "# run_model_and_plot(model_name=\"MyModel\", model=model, X_df=X_df, y=y)\n",
    "\n",
    "# Perform walk-forward validation\n",
    "validation_results = perform_walk_forward_validation(\n",
    "    model_name=\"MyModel\",\n",
    "    model=model,\n",
    "    X_df=X_df,\n",
    "    y=y,\n",
    "    custom_performance_metric=custom_metric,  # Optional custom metric\n",
    ")\n",
    "\n",
    "# Access and analyze the results\n",
    "print(f\"Walk-Forward Validation Results for {validation_results['model_name']}\")\n",
    "print(f\"Errors: {validation_results['errors']}\")\n",
    "print(f\"Custom Metric: {validation_results['custom_metric']}\")  # Replace with actual metric name\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
